# Security Policy

## Responsible Use

This repository contains defensive security research on Chain-of-Thought jailbreak attacks against AI systems.

### Important Notice

This research is provided for **defensive purposes only**. Please review the [LICENSE](LICENSE) file for complete terms of use.

**Permitted Uses:**
- ✅ Defensive security research
- ✅ Educational purposes
- ✅ Security tool development
- ✅ Academic study and citation
- ✅ Internal authorized security testing

**Prohibited Uses:**
- ❌ Malicious attacks on unauthorized systems
- ❌ Weaponization or automated exploitation tools
- ❌ Unauthorized security testing
- ❌ Illegal or unethical activities

## Research Methodology

All testing was conducted:
- In authorized lab environments
- Against systems owned or explicitly authorized for testing
- Following responsible disclosure principles
- With focus on defense development

## What's NOT Included

For responsible disclosure, this repository does NOT contain:
- Working attack prompts or payloads
- Attack framework implementation code
- Automated exploitation tools
- Raw test data or API responses

## Reporting Security Issues

If you discover security vulnerabilities related to this research:

**Email:** scott@perfecxion.ai

Please include:
- Description of the finding
- Steps to reproduce (if applicable)
- Potential impact assessment
- Suggested mitigations (if any)

## Contact

- **Email:** scott@perfecxion.ai
- **Alternative:** scthornton@gmail.com

For questions about appropriate use or to request additional materials for authorized research, contact scott@perfecxion.ai.
